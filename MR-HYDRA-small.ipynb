{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe54664b",
   "metadata": {},
   "source": [
    "# Fit the small model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00d8969b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 datasets to process\n",
      "\n",
      "[1/5] Processing AAPL...\n",
      "Loaded 11224 rows for AAPL\n",
      "\n",
      "============================================================\n",
      "Training model for: AAPL\n",
      "============================================================\n",
      "Data shape after rolling windows: (11214, 10, 17)\n",
      "Train samples: 8971, Test samples: 2243\n",
      "Training Hydra transformer...\n",
      "Training MultiRocket transformer...\n",
      "Training classifier...\n",
      "Test accuracy: 0.4695\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.46      0.90      0.61      1039\n",
      "          Up       0.53      0.10      0.17      1204\n",
      "\n",
      "    accuracy                           0.47      2243\n",
      "   macro avg       0.50      0.50      0.39      2243\n",
      "weighted avg       0.50      0.47      0.37      2243\n",
      "\n",
      "✓ Model saved to models-small//AAPL_mr_hydra_model.pkl\n",
      "\n",
      "[2/5] Processing GE...\n",
      "Loaded 15977 rows for GE\n",
      "\n",
      "============================================================\n",
      "Training model for: GE\n",
      "============================================================\n",
      "Data shape after rolling windows: (15967, 10, 17)\n",
      "Train samples: 12773, Test samples: 3194\n",
      "Training Hydra transformer...\n",
      "Training MultiRocket transformer...\n",
      "Training classifier...\n",
      "Test accuracy: 0.4975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.49      0.55      0.52      1581\n",
      "          Up       0.50      0.44      0.47      1613\n",
      "\n",
      "    accuracy                           0.50      3194\n",
      "   macro avg       0.50      0.50      0.50      3194\n",
      "weighted avg       0.50      0.50      0.50      3194\n",
      "\n",
      "✓ Model saved to models-small//GE_mr_hydra_model.pkl\n",
      "\n",
      "[3/5] Processing IBM...\n",
      "Loaded 15975 rows for IBM\n",
      "\n",
      "============================================================\n",
      "Training model for: IBM\n",
      "============================================================\n",
      "Data shape after rolling windows: (15965, 10, 17)\n",
      "Train samples: 12772, Test samples: 3193\n",
      "Training Hydra transformer...\n",
      "Training MultiRocket transformer...\n",
      "Training classifier...\n",
      "Test accuracy: 0.5014\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.48      0.48      0.48      1522\n",
      "          Up       0.52      0.52      0.52      1671\n",
      "\n",
      "    accuracy                           0.50      3193\n",
      "   macro avg       0.50      0.50      0.50      3193\n",
      "weighted avg       0.50      0.50      0.50      3193\n",
      "\n",
      "✓ Model saved to models-small//IBM_mr_hydra_model.pkl\n",
      "\n",
      "[4/5] Processing JNJ...\n",
      "Loaded 15968 rows for JNJ\n",
      "\n",
      "============================================================\n",
      "Training model for: JNJ\n",
      "============================================================\n",
      "Data shape after rolling windows: (15958, 10, 17)\n",
      "Train samples: 12766, Test samples: 3192\n",
      "Training Hydra transformer...\n",
      "Training MultiRocket transformer...\n",
      "Training classifier...\n",
      "Test accuracy: 0.5197\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.47      0.09      0.15      1516\n",
      "          Up       0.52      0.91      0.67      1676\n",
      "\n",
      "    accuracy                           0.52      3192\n",
      "   macro avg       0.50      0.50      0.41      3192\n",
      "weighted avg       0.50      0.52      0.42      3192\n",
      "\n",
      "✓ Model saved to models-small//JNJ_mr_hydra_model.pkl\n",
      "\n",
      "[5/5] Processing MSFT...\n",
      "Loaded 9899 rows for MSFT\n",
      "\n",
      "============================================================\n",
      "Training model for: MSFT\n",
      "============================================================\n",
      "Data shape after rolling windows: (9889, 10, 17)\n",
      "Train samples: 7911, Test samples: 1978\n",
      "Training Hydra transformer...\n",
      "Training MultiRocket transformer...\n",
      "Training classifier...\n",
      "Test accuracy: 0.4626\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.46      0.90      0.60       902\n",
      "          Up       0.53      0.09      0.16      1076\n",
      "\n",
      "    accuracy                           0.46      1978\n",
      "   macro avg       0.49      0.50      0.38      1978\n",
      "weighted avg       0.50      0.46      0.36      1978\n",
      "\n",
      "✓ Model saved to models-small//MSFT_mr_hydra_model.pkl\n",
      "\n",
      "============================================================\n",
      "TRAINING SUMMARY\n",
      "============================================================\n",
      "Total datasets: 5\n",
      "Successful: 5\n",
      "Failed: 0\n",
      "\n",
      "Detailed results saved to: models-small//training_summary-small.csv\n",
      "\n",
      "Successfully trained models for:\n",
      "  - AAPL\n",
      "  - GE\n",
      "  - IBM\n",
      "  - JNJ\n",
      "  - MSFT\n"
     ]
    }
   ],
   "source": [
    "# mr_hydra_multi_stock_training.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from aeon.transformations.collection.convolution_based import MultiRocket\n",
    "from aeon.transformations.collection.convolution_based import HydraTransformer\n",
    "from aeon.utils.validation import check_n_jobs\n",
    "\n",
    "def load_and_preprocess(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        raise FileNotFoundError(f\"No file at {filename}\")\n",
    "    df = pd.read_csv(filename, parse_dates=[\"Date\"])\n",
    "    df[\"Direction\"] = (df[\"Close\"].shift(-1) > df[\"Close\"]).astype(int)\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "def rolling_windows(df, window_size=10, drop_cols=None):\n",
    "    if drop_cols is None:\n",
    "        drop_cols = [\"Date\", \"Close\", \"Target\", \"Direction\",\n",
    "                    \"High\", \"Low\", \"Open\", \"High_lag1\", \"Low_lag1\", \"Open_lag1\"]\n",
    "    Xs, ys = [], []\n",
    "    features = df.drop(columns=drop_cols, errors='ignore')  # Added errors='ignore'\n",
    "    y = df[\"Direction\"].values\n",
    "    for i in range(window_size, len(df)):\n",
    "        Xs.append(features.iloc[i-window_size : i].values)\n",
    "        ys.append(y[i])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "def reshape_for_aeon(X_3d):\n",
    "    return np.transpose(X_3d, (0, 2, 1))\n",
    "\n",
    "def mr_hydra_train_eval(df, stock_name, window_size=10,\n",
    "                        mr_kernels=500,\n",
    "                        hydra_groups=8, hydra_kernels=4,\n",
    "                        test_ratio=0.2,\n",
    "                        n_jobs=None,\n",
    "                        random_state=42,\n",
    "                        save_path=\"models/\"):\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training model for: {stock_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        Xw, yw = rolling_windows(df, window_size=window_size)\n",
    "        print(f\"Data shape after rolling windows: {Xw.shape}\")\n",
    "        \n",
    "        if len(Xw) < 100:  # Minimum samples check\n",
    "            print(f\"⚠️  Warning: Only {len(Xw)} samples for {stock_name}. Skipping.\")\n",
    "            return False\n",
    "            \n",
    "        scaler = StandardScaler()\n",
    "        ns, ts, nf = Xw.shape\n",
    "        X_flat = Xw.reshape(ns * ts, nf)\n",
    "        X_flat = scaler.fit_transform(X_flat).astype(\"float32\")\n",
    "        X_scaled = X_flat.reshape(ns, ts, nf)\n",
    "        X = reshape_for_aeon(X_scaled)\n",
    "        y = yw\n",
    "\n",
    "        split_idx = int((1 - test_ratio) * ns)\n",
    "        X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "        y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "        \n",
    "        print(f\"Train samples: {len(X_train)}, Test samples: {len(X_test)}\")\n",
    "\n",
    "        if n_jobs is None:\n",
    "            n_jobs = check_n_jobs(-1)\n",
    "\n",
    "        print(\"Training Hydra transformer...\")\n",
    "        hydra = HydraTransformer(n_groups=hydra_groups,\n",
    "                      n_kernels=hydra_kernels,\n",
    "                      random_state=random_state)\n",
    "\n",
    "        X_hydra_train = hydra.fit_transform(X_train, y_train)\n",
    "        X_hydra_test = hydra.transform(X_test)\n",
    "\n",
    "        print(\"Training MultiRocket transformer...\")\n",
    "        mr = MultiRocket(n_kernels=mr_kernels,\n",
    "                         n_jobs=n_jobs,\n",
    "                         random_state=random_state)\n",
    "        X_mr_train = mr.fit_transform(X_train, y_train)\n",
    "        X_mr_test = mr.transform(X_test)\n",
    "\n",
    "        X_train_full = np.hstack([X_hydra_train, X_mr_train])\n",
    "        X_test_full = np.hstack([X_hydra_test, X_mr_test])\n",
    "\n",
    "        print(\"Training classifier...\")\n",
    "        clf = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10))\n",
    "        clf.fit(X_train_full, y_train)\n",
    "\n",
    "        y_pred = clf.predict(X_test_full)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Test accuracy: {acc:.4f}\")\n",
    "        print(classification_report(y_test, y_pred, target_names=[\"Down\", \"Up\"]))\n",
    "\n",
    "        # Save model components\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        model_data = {\n",
    "            'scaler': scaler,\n",
    "            'hydra': hydra,\n",
    "            'multirocket': mr,\n",
    "            'classifier': clf,\n",
    "            'window_size': window_size,\n",
    "            'n_features': nf,\n",
    "            'stock_name': stock_name,\n",
    "            'test_accuracy': acc,\n",
    "            'drop_cols': [\"Date\", \"Close\", \"Target\", \"Direction\",\n",
    "                         \"High\", \"Low\", \"Open\", \"High_lag1\", \"Low_lag1\", \"Open_lag1\"]\n",
    "        }\n",
    "        \n",
    "        model_filename = f\"{save_path}/{stock_name}_mr_hydra_model.pkl\"\n",
    "        joblib.dump(model_data, model_filename)\n",
    "        print(f\"✓ Model saved to {model_filename}\")\n",
    "        \n",
    "        # Clean up memory\n",
    "        del hydra, mr, clf, X_train_full, X_test_full\n",
    "        gc.collect()\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error training {stock_name}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def train_all_stocks(data_dir=\"data/processed/stock_data/\", save_path=\"models-small/\", **kwargs):\n",
    "    \"\"\"Train models for all stock datasets in the directory\"\"\"\n",
    "    \n",
    "    # Find all CSV files\n",
    "    csv_files = glob.glob(os.path.join(data_dir, \"*.csv\"))\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(f\"No CSV files found in {data_dir}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(csv_files)} datasets to process\")\n",
    "    \n",
    "    results = []\n",
    "    successful = 0\n",
    "    failed = 0\n",
    "    \n",
    "    for i, filepath in enumerate(csv_files, 1):\n",
    "        # Extract stock name from filename\n",
    "        filename = os.path.basename(filepath)\n",
    "        stock_name = filename.replace('_daily_features.csv', '').replace('.csv', '')\n",
    "        \n",
    "        print(f\"\\n[{i}/{len(csv_files)}] Processing {stock_name}...\")\n",
    "        \n",
    "        try:\n",
    "            df = load_and_preprocess(filepath)\n",
    "            print(f\"Loaded {len(df)} rows for {stock_name}\")\n",
    "            \n",
    "            success = mr_hydra_train_eval(df, stock_name, save_path=save_path, **kwargs)\n",
    "            \n",
    "            if success:\n",
    "                successful += 1\n",
    "                results.append({'stock': stock_name, 'status': 'success', 'rows': len(df)})\n",
    "            else:\n",
    "                failed += 1\n",
    "                results.append({'stock': stock_name, 'status': 'failed', 'rows': len(df)})\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to process {stock_name}: {str(e)}\")\n",
    "            failed += 1\n",
    "            results.append({'stock': stock_name, 'status': 'error', 'error': str(e)})\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"TRAINING SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total datasets: {len(csv_files)}\")\n",
    "    print(f\"Successful: {successful}\")\n",
    "    print(f\"Failed: {failed}\")\n",
    "    \n",
    "    # Save results summary\n",
    "    results_df = pd.DataFrame(results)\n",
    "    summary_path = f\"{save_path}/training_summary-small.csv\"\n",
    "    results_df.to_csv(summary_path, index=False)\n",
    "    print(f\"\\nDetailed results saved to: {summary_path}\")\n",
    "    \n",
    "    # Show successful models\n",
    "    successful_models = [r['stock'] for r in results if r['status'] == 'success']\n",
    "    if successful_models:\n",
    "        print(f\"\\nSuccessfully trained models for:\")\n",
    "        for stock in successful_models:\n",
    "            print(f\"  - {stock}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_all_stocks(\n",
    "        data_dir=\"data/processed/stock_data/\",\n",
    "        save_path=\"models-small/\",\n",
    "        window_size=10,\n",
    "        mr_kernels=500,\n",
    "        hydra_groups=8,\n",
    "        hydra_kernels=4,\n",
    "        test_ratio=0.2\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf210",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
