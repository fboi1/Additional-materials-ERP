{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cad8acf2",
   "metadata": {},
   "source": [
    "# Fit the SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ae46529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing AAPL_daily ===\n",
      "SVM Accuracy: 0.4664, AUC: 0.4872\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.97      0.63      1040\n",
      "           1       0.54      0.04      0.07      1205\n",
      "\n",
      "    accuracy                           0.47      2245\n",
      "   macro avg       0.50      0.50      0.35      2245\n",
      "weighted avg       0.51      0.47      0.33      2245\n",
      "\n",
      "Saved model to summary\\svm\\AAPL_daily_svm_model.pkl and scaler to summary\\svm\\AAPL_daily_scaler.pkl\n",
      "\n",
      "=== Processing GE_daily ===\n",
      "SVM Accuracy: 0.4966, AUC: 0.5004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.58      0.53      1582\n",
      "           1       0.50      0.42      0.46      1614\n",
      "\n",
      "    accuracy                           0.50      3196\n",
      "   macro avg       0.50      0.50      0.49      3196\n",
      "weighted avg       0.50      0.50      0.49      3196\n",
      "\n",
      "Saved model to summary\\svm\\GE_daily_svm_model.pkl and scaler to summary\\svm\\GE_daily_scaler.pkl\n",
      "\n",
      "=== Processing IBM_daily ===\n",
      "SVM Accuracy: 0.5161, AUC: 0.5021\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.35      0.41      1524\n",
      "           1       0.53      0.67      0.59      1671\n",
      "\n",
      "    accuracy                           0.52      3195\n",
      "   macro avg       0.51      0.51      0.50      3195\n",
      "weighted avg       0.51      0.52      0.50      3195\n",
      "\n",
      "Saved model to summary\\svm\\IBM_daily_svm_model.pkl and scaler to summary\\svm\\IBM_daily_scaler.pkl\n",
      "\n",
      "=== Processing JNJ_daily ===\n",
      "SVM Accuracy: 0.5147, AUC: 0.4946\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.07      0.11      1518\n",
      "           1       0.52      0.92      0.67      1676\n",
      "\n",
      "    accuracy                           0.51      3194\n",
      "   macro avg       0.48      0.49      0.39      3194\n",
      "weighted avg       0.48      0.51      0.40      3194\n",
      "\n",
      "Saved model to summary\\svm\\JNJ_daily_svm_model.pkl and scaler to summary\\svm\\JNJ_daily_scaler.pkl\n",
      "\n",
      "=== Processing MSFT_daily ===\n",
      "SVM Accuracy: 0.5278, AUC: 0.5048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.10      0.16       903\n",
      "           1       0.54      0.89      0.67      1077\n",
      "\n",
      "    accuracy                           0.53      1980\n",
      "   macro avg       0.48      0.49      0.42      1980\n",
      "weighted avg       0.49      0.53      0.44      1980\n",
      "\n",
      "Saved model to summary\\svm\\MSFT_daily_svm_model.pkl and scaler to summary\\svm\\MSFT_daily_scaler.pkl\n",
      "\n",
      "Summary saved to summary\\stock_data_model_summary_svm.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from glob import glob\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Paths\n",
    "input_folder = \"data/processed/stock_data\"\n",
    "summary_folder = \"summary\"\n",
    "model_folder = os.path.join(summary_folder, \"svm\")  # Changed from \"random_forest\"\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "summary_results = []\n",
    "\n",
    "for file_path in glob(os.path.join(input_folder, \"*.csv\")):\n",
    "    stock_name = os.path.basename(file_path).replace(\"_features.csv\", \"\")\n",
    "    print(f\"\\n=== Processing {stock_name} ===\")\n",
    "\n",
    "    # Load data\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Create binary target: 1 if price goes up tomorrow, 0 if down\n",
    "    df['Direction'] = (df['Close'].shift(-1) > df['Close']).astype(int)\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Features\n",
    "    X = df.drop(columns=[\n",
    "        \"Date\", \"Close\", \"Target\", \"Direction\",\n",
    "        \"High\", \"Low\", \"Open\", \"High_lag1\", \"Low_lag1\", \"Open_lag1\"\n",
    "    ])\n",
    "    y = df['Direction']\n",
    "\n",
    "    # Split\n",
    "    train_size = int(len(X) * 0.8)\n",
    "    X_train, X_test = X.iloc[:train_size], X.iloc[train_size:]\n",
    "    y_train, y_test = y.iloc[:train_size], y.iloc[train_size:]\n",
    "\n",
    "    # Scale features (important for SVM)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # SVM Classifier with probability estimation enabled\n",
    "    svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', probability=True, random_state=42)\n",
    "    svm_model.fit(X_train_scaled, y_train)\n",
    "    y_pred = svm_model.predict(X_test_scaled)\n",
    "    y_proba = svm_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    print(f\"SVM Accuracy: {acc:.4f}, AUC: {auc:.4f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Save model and scaler\n",
    "    model_path = os.path.join(model_folder, f\"{stock_name}_svm_model.pkl\")\n",
    "    scaler_path = os.path.join(model_folder, f\"{stock_name}_scaler.pkl\")\n",
    "    joblib.dump(svm_model, model_path)\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "    print(f\"Saved model to {model_path} and scaler to {scaler_path}\")\n",
    "\n",
    "    # Append metrics to summary\n",
    "    summary_results.append({\n",
    "        \"Stock\": stock_name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"AUC\": auc\n",
    "    })\n",
    "\n",
    "# Save summary\n",
    "summary_df = pd.DataFrame(summary_results)\n",
    "summary_file = os.path.join(summary_folder, \"stock_data_model_summary_svm.csv\")\n",
    "summary_df.to_csv(summary_file, index=False)\n",
    "print(f\"\\nSummary saved to {summary_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0383bf3",
   "metadata": {},
   "source": [
    "# Test the SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4df684b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing AAPL_daily ===\n",
      "  SVM Accuracy: 0.4664, AUC: 0.4872\n",
      "  ✓ AAPL_daily: PF=0.854, Sharpe=-0.85, Sortino=-1.16, p=0.676\n",
      "    Saved time series to backtest_results_svm_donchian\\AAPL_daily_strat_timeseries.csv\n",
      "\n",
      "=== Processing GE_daily ===\n",
      "  SVM Accuracy: 0.4966, AUC: 0.5004\n",
      "  ✓ GE_daily: PF=1.051, Sharpe=0.26, Sortino=0.35, p=0.748\n",
      "    Saved time series to backtest_results_svm_donchian\\GE_daily_strat_timeseries.csv\n",
      "\n",
      "=== Processing IBM_daily ===\n",
      "  SVM Accuracy: 0.5161, AUC: 0.5021\n",
      "  ✓ IBM_daily: PF=0.987, Sharpe=-0.07, Sortino=-0.09, p=0.358\n",
      "    Saved time series to backtest_results_svm_donchian\\IBM_daily_strat_timeseries.csv\n",
      "\n",
      "=== Processing JNJ_daily ===\n",
      "  SVM Accuracy: 0.5147, AUC: 0.4946\n",
      "  ✓ JNJ_daily: PF=1.123, Sharpe=0.62, Sortino=0.81, p=0.226\n",
      "    Saved time series to backtest_results_svm_donchian\\JNJ_daily_strat_timeseries.csv\n",
      "\n",
      "=== Processing MSFT_daily ===\n",
      "  SVM Accuracy: 0.5278, AUC: 0.5048\n",
      "  ✓ MSFT_daily: PF=1.207, Sharpe=1.03, Sortino=1.42, p=0.682\n",
      "    Saved time series to backtest_results_svm_donchian\\MSFT_daily_strat_timeseries.csv\n",
      "\n",
      "Summary saved to: backtest_results_svm_donchian\\svm_donchian_evaluation_summary.csv\n",
      "\n",
      "Top 5 by lowest p-value:\n",
      "     stock  p_value  profit_factor    sharpe   sortino  total_strategy_return\n",
      " JNJ_daily    0.226       1.122667  0.622805  0.814378               2.285032\n",
      " IBM_daily    0.358       0.987401 -0.066260 -0.086134              -0.419993\n",
      "AAPL_daily    0.676       0.853636 -0.852705 -1.157349              -0.927296\n",
      "MSFT_daily    0.682       1.207311  1.032590  1.421719               6.291945\n",
      "  GE_daily    0.748       1.051210  0.261173  0.351907               0.500720\n",
      "\n",
      "Top 5 by Sharpe:\n",
      "     stock    sharpe  p_value  profit_factor  total_strategy_return\n",
      "MSFT_daily  1.032590    0.682       1.207311               6.291945\n",
      " JNJ_daily  0.622805    0.226       1.122667               2.285032\n",
      "  GE_daily  0.261173    0.748       1.051210               0.500720\n",
      " IBM_daily -0.066260    0.358       0.987401              -0.419993\n",
      "AAPL_daily -0.852705    0.676       0.853636              -0.927296\n"
     ]
    }
   ],
   "source": [
    "# evaluate_svm_donchian.py\n",
    "import os\n",
    "import warnings\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# -------------------------------\n",
    "# Config\n",
    "# -------------------------------\n",
    "INPUT_FOLDER   = \"data/processed/stock_data\"\n",
    "SUMMARY_FOLDER = \"summary\"\n",
    "MODEL_FOLDER   = os.path.join(SUMMARY_FOLDER, \"svm\")\n",
    "RESULTS_FOLDER = \"backtest_results_svm_donchian\"\n",
    "\n",
    "DONCHIAN_PERIOD = 20\n",
    "CONFIDENCE_THRESHOLD = 0.0      # raise if you want to filter by higher model confidence\n",
    "TEST_SPLIT = 0.2                # last 20% as test\n",
    "TRADING_DAYS = 252\n",
    "RISK_FREE_ANNUAL = 0.0          # set e.g. 0.03 for 3%\n",
    "N_PERMUTATIONS = 500            # MC permutations per stock\n",
    "\n",
    "os.makedirs(MODEL_FOLDER, exist_ok=True)\n",
    "os.makedirs(SUMMARY_FOLDER, exist_ok=True)\n",
    "os.makedirs(RESULTS_FOLDER, exist_ok=True)\n",
    "\n",
    "# -------------------------------\n",
    "# Helpers\n",
    "# -------------------------------\n",
    "def sortino_ratio(returns, rf_annual=0.0, periods=TRADING_DAYS):\n",
    "    \"\"\"Annualized Sortino: (mean - rf)/downside_std * sqrt(periods).\"\"\"\n",
    "    if len(returns) == 0:\n",
    "        return 0.0\n",
    "    rf_daily = rf_annual / periods\n",
    "    downside = returns[returns < rf_daily]\n",
    "    if downside.size == 0:\n",
    "        # no downside volatility -> treat as very high risk-adjusted perf\n",
    "        return np.inf\n",
    "    downside_std = downside.std(ddof=0)\n",
    "    if downside_std == 0:\n",
    "        return np.inf\n",
    "    return ((returns.mean() - rf_daily) / downside_std) * np.sqrt(periods)\n",
    "\n",
    "def sharpe_ratio(returns, rf_annual=0.0, periods=TRADING_DAYS):\n",
    "    \"\"\"Annualized Sharpe using population std (ddof=0) to be robust in small samples.\"\"\"\n",
    "    if len(returns) == 0:\n",
    "        return 0.0\n",
    "    std = returns.std(ddof=0)\n",
    "    if std == 0:\n",
    "        return 0.0\n",
    "    rf_daily = rf_annual / periods\n",
    "    return ((returns.mean() - rf_daily) / std) * np.sqrt(periods)\n",
    "\n",
    "def profit_factor(returns):\n",
    "    gains = returns[returns > 0].sum()\n",
    "    losses = np.abs(returns[returns < 0].sum())\n",
    "    if losses == 0:\n",
    "        return np.inf if gains > 0 else 0.0\n",
    "    return gains / losses\n",
    "\n",
    "def donchian_breakout_strategy(df, preds, conf, donchian_period=DONCHIAN_PERIOD, conf_th=CONFIDENCE_THRESHOLD):\n",
    "    \"\"\"\n",
    "    Long if breakout above Donchian high and model predicts up (1) with confidence > threshold.\n",
    "    Short if breakout below Donchian low and model predicts down (0) with confidence > threshold.\n",
    "    Positions are held until the next signal (ffill).\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "    out[\"Pred\"] = preds\n",
    "    out[\"Conf\"] = np.abs(conf)\n",
    "\n",
    "    out[\"Donchian_High\"] = out[\"High\"].rolling(window=donchian_period).max()\n",
    "    out[\"Donchian_Low\"]  = out[\"Low\"].rolling(window=donchian_period).min()\n",
    "\n",
    "    out[\"Long_Signal\"]  = (out[\"Close\"] > out[\"Donchian_High\"].shift(1)) & (out[\"Pred\"] == 1) & (out[\"Conf\"] > conf_th)\n",
    "    out[\"Short_Signal\"] = (out[\"Close\"] < out[\"Donchian_Low\"].shift(1))  & (out[\"Pred\"] == 0) & (out[\"Conf\"] > conf_th)\n",
    "\n",
    "    out[\"Position\"] = 0\n",
    "    out.loc[out[\"Long_Signal\"], \"Position\"] = 1\n",
    "    out.loc[out[\"Short_Signal\"], \"Position\"] = -1\n",
    "    out[\"Position\"] = out[\"Position\"].replace(0, np.nan).ffill().fillna(0)\n",
    "\n",
    "    out[\"Market_Return\"]   = out[\"Close\"].pct_change()\n",
    "    out[\"Strategy_Return\"] = out[\"Position\"].shift(1) * out[\"Market_Return\"]\n",
    "    out = out.dropna(subset=[\"Market_Return\", \"Strategy_Return\"])\n",
    "    return out\n",
    "\n",
    "def monte_carlo_pvalue(df, preds, conf, n_permutations=N_PERMUTATIONS):\n",
    "    \"\"\"Permutation test on profit factor by shuffling predictions only.\"\"\"\n",
    "    # actual\n",
    "    strat_df = donchian_breakout_strategy(df, preds, conf)\n",
    "    actual_rets = strat_df[\"Strategy_Return\"].dropna()\n",
    "    if len(actual_rets) == 0:\n",
    "        return 0.0, np.array([0.0]), 1.0\n",
    "    actual_pf = profit_factor(actual_rets)\n",
    "\n",
    "    rnd_pfs = np.zeros(n_permutations, dtype=float)\n",
    "    for i in range(n_permutations):\n",
    "        shuf_preds = np.random.permutation(preds)\n",
    "        try:\n",
    "            rnd_df = donchian_breakout_strategy(df, shuf_preds, conf)\n",
    "            rnd_rets = rnd_df[\"Strategy_Return\"].dropna()\n",
    "            rnd_pfs[i] = profit_factor(rnd_rets) if len(rnd_rets) else 0.0\n",
    "        except Exception:\n",
    "            rnd_pfs[i] = 0.0\n",
    "\n",
    "    p_val = (rnd_pfs >= actual_pf).mean()\n",
    "    return actual_pf, rnd_pfs, p_val\n",
    "\n",
    "# -------------------------------\n",
    "# Main loop\n",
    "# -------------------------------\n",
    "all_rows = []\n",
    "\n",
    "files = sorted(glob(os.path.join(INPUT_FOLDER, \"*_features.csv\")))\n",
    "if not files:\n",
    "    print(f\"No files found in: {INPUT_FOLDER}\")\n",
    "\n",
    "for file_path in files:\n",
    "    stock_name = os.path.basename(file_path).replace(\"_features.csv\", \"\")\n",
    "    print(f\"\\n=== Processing {stock_name} ===\")\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, parse_dates=[\"Date\"], infer_datetime_format=True)\n",
    "    except Exception:\n",
    "        df = pd.read_csv(file_path)  # fallback if Date not parseable\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # binary target\n",
    "    if \"Close\" not in df.columns or \"High\" not in df.columns or \"Low\" not in df.columns:\n",
    "        print(f\"  ⚠️  Missing required OHLC columns for {stock_name}; skipping.\")\n",
    "        continue\n",
    "\n",
    "    df[\"Direction\"] = (df[\"Close\"].shift(-1) > df[\"Close\"]).astype(int)\n",
    "    df = df.dropna()\n",
    "\n",
    "    # features\n",
    "    drop_cols = [\n",
    "        \"Date\", \"Close\", \"Target\", \"Direction\",\n",
    "        \"High\", \"Low\", \"Open\", \"High_lag1\", \"Low_lag1\", \"Open_lag1\"\n",
    "    ]\n",
    "    X = df.drop(columns=[c for c in drop_cols if c in df.columns], errors=\"ignore\")\n",
    "    y = df[\"Direction\"]\n",
    "\n",
    "    if len(X) < 50:\n",
    "        print(f\"  ⚠️  Not enough rows for {stock_name}; skipping.\")\n",
    "        continue\n",
    "\n",
    "    # split (time-ordered)\n",
    "    split_idx = int(len(X) * (1 - TEST_SPLIT))\n",
    "    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "    test_df = df.iloc[split_idx:].copy()\n",
    "\n",
    "    # scale + SVM\n",
    "    scaler = StandardScaler()\n",
    "    X_train_s = scaler.fit_transform(X_train)\n",
    "    X_test_s  = scaler.transform(X_test)\n",
    "\n",
    "    svm = SVC(kernel=\"rbf\", C=1.0, gamma=\"scale\", probability=True, random_state=42)\n",
    "    svm.fit(X_train_s, y_train)\n",
    "\n",
    "    y_pred  = svm.predict(X_test_s)\n",
    "    y_proba = svm.predict_proba(X_test_s)[:, 1]\n",
    "    # confidence as distance-from-0.5 probability (symmetric)\n",
    "    conf = np.abs(y_proba - 0.5) * 2.0\n",
    "\n",
    "    # classification metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    try:\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "    except ValueError:\n",
    "        auc = np.nan\n",
    "\n",
    "    print(f\"  SVM Accuracy: {acc:.4f}, AUC: {auc:.4f}\" if not np.isnan(auc) else f\"  SVM Accuracy: {acc:.4f}\")\n",
    "\n",
    "    # backtest with Donchian + predictions\n",
    "    try:\n",
    "        strat_df = donchian_breakout_strategy(test_df, y_pred, conf)\n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Strategy error for {stock_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    strat_rets  = strat_df[\"Strategy_Return\"].dropna()\n",
    "    market_rets = strat_df[\"Market_Return\"].dropna()\n",
    "\n",
    "    if len(strat_rets) == 0:\n",
    "        print(f\"  ⚠️  No strategy returns for {stock_name}; skipping.\")\n",
    "        continue\n",
    "\n",
    "    # performance\n",
    "    total_strategy_return = (1 + strat_rets).prod() - 1\n",
    "    total_market_return   = (1 + market_rets).prod() - 1\n",
    "    win_rate = (strat_rets > 0).mean()\n",
    "\n",
    "    # trades: position changes / 2\n",
    "    trades = strat_df[\"Position\"].diff().abs().fillna(0).sum() / 2\n",
    "\n",
    "    # risk metrics\n",
    "    sr = sharpe_ratio(strat_rets, rf_annual=RISK_FREE_ANNUAL, periods=TRADING_DAYS)\n",
    "    sortino = sortino_ratio(strat_rets, rf_annual=RISK_FREE_ANNUAL, periods=TRADING_DAYS)\n",
    "\n",
    "    # profit factor + permutation p-value\n",
    "    pf_actual, rnd_pfs, p_val = monte_carlo_pvalue(test_df, y_pred, conf, n_permutations=N_PERMUTATIONS)\n",
    "\n",
    "    row = {\n",
    "        \"stock\": stock_name,\n",
    "        \"test_samples\": len(test_df),\n",
    "        \"accuracy\": acc,\n",
    "        \"auc\": auc,\n",
    "        \"total_strategy_return\": total_strategy_return,\n",
    "        \"total_market_return\": total_market_return,\n",
    "        \"excess_return\": total_strategy_return - total_market_return,\n",
    "        \"profit_factor\": pf_actual,\n",
    "        \"p_value\": p_val,\n",
    "        \"sharpe\": sr,\n",
    "        \"sortino\": sortino,\n",
    "        \"win_rate\": win_rate,\n",
    "        \"num_trades\": trades,\n",
    "        \"test_start\": test_df[\"Date\"].min() if \"Date\" in test_df.columns else np.nan,\n",
    "        \"test_end\": test_df[\"Date\"].max() if \"Date\" in test_df.columns else np.nan,\n",
    "    }\n",
    "    all_rows.append(row)\n",
    "\n",
    "    # per-stock CSV\n",
    "    out_stock_csv = os.path.join(RESULTS_FOLDER, f\"{stock_name}_strat_timeseries.csv\")\n",
    "    cols_to_save = [\"Date\", \"Close\", \"Position\", \"Market_Return\", \"Strategy_Return\",\n",
    "                    \"Donchian_High\", \"Donchian_Low\", \"Pred\", \"Conf\"]\n",
    "    cols_to_save = [c for c in cols_to_save if c in strat_df.columns]\n",
    "    strat_df.to_csv(out_stock_csv, index=False)\n",
    "    print(f\"  ✓ {stock_name}: PF={pf_actual:.3f}, Sharpe={sr:.2f}, Sortino={sortino:.2f}, p={p_val:.3f}\")\n",
    "    print(f\"    Saved time series to {out_stock_csv}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Save master summary\n",
    "# -------------------------------\n",
    "if all_rows:\n",
    "    results_df = pd.DataFrame(all_rows)\n",
    "    # rank: primary by p_value asc, secondary by sharpe desc\n",
    "    results_df = results_df.sort_values(by=[\"p_value\", \"sharpe\"], ascending=[True, False])\n",
    "    summary_csv = os.path.join(RESULTS_FOLDER, \"svm_donchian_evaluation_summary.csv\")\n",
    "    results_df.to_csv(summary_csv, index=False)\n",
    "    print(f\"\\nSummary saved to: {summary_csv}\")\n",
    "\n",
    "    # quick console summary\n",
    "    print(\"\\nTop 5 by lowest p-value:\")\n",
    "    print(results_df[[\"stock\", \"p_value\", \"profit_factor\", \"sharpe\", \"sortino\", \"total_strategy_return\"]].head(5).to_string(index=False))\n",
    "\n",
    "    print(\"\\nTop 5 by Sharpe:\")\n",
    "    print(results_df.sort_values(\"sharpe\", ascending=False)[[\"stock\", \"sharpe\", \"p_value\", \"profit_factor\", \"total_strategy_return\"]].head(5).to_string(index=False))\n",
    "else:\n",
    "    print(\"\\nNo successful evaluations to summarize.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock-predict",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
